\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\title{\vspace{-2cm}Matrix Operations Notes}
\author{}
\date{}

\begin{document}

\maketitle

\section{Matrix Addition}
Matrix addition is performed element-wise. If \( A \) and \( B \) are two matrices of the same dimensions \( m \times n \), their sum \( C = A + B \) is defined as:
\[
C_{ij} = A_{ij} + B_{ij}
\]
where \( i \) and \( j \) are the row and column indices.

\section{Matrix Subtraction}
Matrix subtraction is similar to addition and is also performed element-wise. If \( A \) and \( B \) are two matrices of the same dimensions \( m \times n \), their difference \( C = A - B \) is defined as:
\[
C_{ij} = A_{ij} - B_{ij}
\]

\section{Matrix Multiplication}
Matrix multiplication is not element-wise. If \( A \) is an \( m \times n \) matrix and \( B \) is an \( n \times p \) matrix, their product \( C = A \cdot B \) is an \( m \times p \) matrix defined as:
\[
C_{ij} = \sum_{k=1}^{n} A_{ik} B_{kj}
\]
where \( i \) and \( j \) are the row and column indices, and \( k \) is the summation index.

\section{Matrix Transposition}
The transpose of a matrix \( A \), denoted \( A^T \), is obtained by swapping its rows and columns. If \( A \) is an \( m \times n \) matrix, \( A^T \) is an \( n \times m \) matrix defined as:
\[
(A^T)_{ij} = A_{ji}
\]

\section{Determinants}
The determinant of a square matrix \( A \) is a scalar value that provides important properties about the matrix, such as whether it is invertible. For a \( 2 \times 2 \) matrix 
\[
A = \begin{bmatrix}
a & b \\
c & d
\end{bmatrix},
\]
the determinant is calculated as:
\[
\det(A) = ad - bc
\]
For larger matrices, the determinant can be computed using various methods, such as cofactor expansion or row reduction.

\section{Identity Matrix}
The identity matrix \( I_n \) of size \( n \times n \) is a square matrix with ones on the diagonal and zeros elsewhere. It serves as the multiplicative identity for square matrices of size \( n \times n \) in matrix multiplication:
\[
I_n = \begin{bmatrix}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & 1
\end{bmatrix}
\]

\section{Matrix Inversion}
The inverse of a square matrix \( A \), denoted \( A^{-1} \), satisfies:
\[
A \cdot A^{-1} = I
\]
where \( I \) is the identity matrix. A matrix is invertible if and only if it is square and its determinant \( \det(A) \neq 0 \).

\subsection{Example: Matrix Inversion}
Consider a \( 2 \times 2 \) matrix \( A \):
\[
A = \begin{bmatrix}
a & b \\
c & d
\end{bmatrix}
\]
The inverse of \( A \), denoted \( A^{-1} \), is given by:
\[
A^{-1} = \frac{1}{\det(A)} \begin{bmatrix}
d & -b \\
-c & a
\end{bmatrix}
\]
where \( \det(A) = ad - bc \) is the determinant of \( A \). For \( A \) to be invertible, \( \det(A) \neq 0 \).

\section{Proof: Inverse of Product of Two Matrices}
Let \( A \) and \( B \) be invertible matrices of the same size. We aim to prove that:
\[
(AB)^{-1} = B^{-1}A^{-1}
\]

\subsection*{Proof}
By the definition of the inverse of a matrix, we know:
\[
(AB)(AB)^{-1} = I
\]
where \( I \) is the identity matrix.

Substitute \( (AB)^{-1} = B^{-1}A^{-1} \) into the equation:
\[
(AB)(B^{-1}A^{-1}) = I
\]

Using the associative property of matrix multiplication:
\[
A(BB^{-1})A^{-1} = I
\]

Since \( BB^{-1} = I \):
\[
AIA^{-1} = I
\]

And \( AI = A \), so:
\[
AA^{-1} = I
\]

Finally, \( AA^{-1} = I \) holds true, proving that:
\[
(AB)^{-1} = B^{-1}A^{-1}
\]
\[
\qed
\]

\section{Proof: Inverse of Transpose of a Matrix}
Let \( A \) be an invertible matrix. We aim to prove that \( A^T \) is also invertible and that:
\[
(A^T)^{-1} = (A^{-1})^T
\]

\subsection*{Proof}
Since \( A \) is invertible, we know:
\[
A \cdot A^{-1} = I
\]
where \( I \) is the identity matrix.

Taking the transpose of both sides:
\[
(A \cdot A^{-1})^T = I^T
\]

Using the property of transposes that \( (XY)^T = Y^T X^T \):
\[
(A^{-1})^T \cdot A^T = I^T
\]

Since \( I^T = I \):
\[
(A^{-1})^T \cdot A^T = I
\]

By the definition of the inverse of a matrix, \( A^T \) is invertible, and its inverse is \( (A^{-1})^T \). Thus:
\[
(A^T)^{-1} = (A^{-1})^T
\]
\[
\qed
\]

\section{Proof: Uniqueness of Matrix Inverse}
Let \( A \) be an invertible matrix. We aim to prove that the inverse of \( A \) is unique.

\subsection*{Proof}
Suppose \( B \) and \( C \) are both inverses of \( A \). By the definition of the inverse, we have:
\[
AB = I \quad \text{and} \quad AC = I
\]
where \( I \) is the identity matrix.

Consider \( B \) multiplied by \( AC \):
\[
B(AC) = B \cdot I = B
\]

Using the associative property of matrix multiplication:
\[
(BA)C = B
\]

Since \( AB = I \), we substitute \( I \) for \( BA \):
\[
IC = B
\]

And \( IC = C \), so:
\[
C = B
\]

Thus, \( B \) and \( C \) are the same, proving that the inverse of \( A \) is unique.
\[
\qed
\]


\section{Proof: Area of a Parallelogram is the absolute value of the determinant}
Consider the parallelogram formed by two vectors drawn from the origin to the points \( (a, b) \) and \( (c, d) \). The area of this parallelogram can be computed using the determinant of a \( 2 \times 2 \) matrix.

\subsection*{Formula for Area}
The area \( \text{Area} \) is given by:
\[
\text{Area} = \left| \det \begin{pmatrix} a & b \\ c & d \end{pmatrix} \right|
\]

\subsection*{Proof}
Consider the parallelogram formed by vectors \(\vec{u} = (a, b)\) and \(\vec{v} = (c, d)\) from the origin to points \((a, b)\) and \((c, d)\). The area is given by the absolute value of the determinant of the matrix with these vectors as rows:
\[
\text{Area} = \left| \det \begin{pmatrix} a & b \\ c & d \end{pmatrix} \right| = |ad - bc|
\]
This follows from the geometric interpretation of the determinant as the signed area of the parallelogram, with the absolute value ensuring a positive area.
\end{document}